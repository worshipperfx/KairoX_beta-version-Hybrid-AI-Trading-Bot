{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10521289,"sourceType":"datasetVersion","datasetId":6511716}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tf2onnx\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T06:40:03.061764Z","iopub.execute_input":"2025-08-10T06:40:03.062077Z","iopub.status.idle":"2025-08-10T06:40:09.707244Z","shell.execute_reply.started":"2025-08-10T06:40:03.062040Z","shell.execute_reply":"2025-08-10T06:40:09.705942Z"}},"outputs":[{"name":"stdout","text":"Collecting tf2onnx\n  Downloading tf2onnx-1.16.1-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.26.4)\nRequirement already satisfied: onnx>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.17.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (2.32.3)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.17.0)\nRequirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (24.3.25)\nRequirement already satisfied: protobuf~=3.20 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (3.20.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.1->tf2onnx) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.1->tf2onnx) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.1->tf2onnx) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.1->tf2onnx) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.1->tf2onnx) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.1->tf2onnx) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2024.12.14)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.14.1->tf2onnx) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.14.1->tf2onnx) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.1->tf2onnx) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.14.1->tf2onnx) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.14.1->tf2onnx) (2024.2.0)\nDownloading tf2onnx-1.16.1-py3-none-any.whl (455 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.8/455.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tf2onnx\nSuccessfully installed tf2onnx-1.16.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as py\nimport numpy as np\nimport os\nimport tensorflow as tf\nimport onnx \nimport tf2onnx\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, concatenate\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-10T06:40:09.708623Z","iopub.execute_input":"2025-08-10T06:40:09.709032Z","iopub.status.idle":"2025-08-10T06:40:26.284788Z","shell.execute_reply.started":"2025-08-10T06:40:09.708996Z","shell.execute_reply":"2025-08-10T06:40:26.283790Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class TradeDataLoader:\n    def __init__(self, file_path=\"/kaggle/input/real-real-trading-dataset/Trading data.xlsx\"):\n        self.file_path = file_path\n        self.data = None\n\n    def load_data(self):\n        self.data = py.read_excel(self.file_path)\n        self.data.drop(columns=['BOS', 'LOWER TF', 'Date'], inplace=True, errors='ignore')\n        print(f\"Data loaded from {self.file_path}\")\n        print(\"Original Tabular Data Shape:\", self.data.shape)\n        print(self.data.head(5))\n\n    def preprocess_data(self):\n        if self.data is not None:\n            print(\"Step 1 - Original Data Shape:\", self.data.shape)\n            print(self.data.head())  # Print first few rows\n    \n        \n            print(\"Step 2 - Unique TP/SL values before cleaning:\", self.data['TP/SL'].unique())\n            self.data['TP/SL'] = self.data['TP/SL'].str.replace('n', '-', regex=False)\n            self.data['TP/SL'] = self.data['TP/SL'].str.split('-').str[0].str.strip()\n            self.data['Price at 800 EMA'] = self.data['Price at 800 EMA'].str.split('-').str[0].str.strip()\n            print(\"Step 2 - Unique TP/SL values after cleaning:\", self.data['TP/SL'].unique())\n            print(\"Step 2 - Unique Price at 800 EMA values after cleaning:\", self.data['Price at 800 EMA'].unique())\n    \n            \n            self.data = py.get_dummies(self.data, columns=['Timeframe', 'Trade Type', 'TP/SL', 'Price at 800 EMA', 'Hit 50EMA'])\n    \n            print(\"Step 3 - Shape After Encoding:\", self.data.shape)\n            print(\"Step 3 - Columns After Encoding:\", self.data.columns.tolist())\n    \n            \n            bool_columns = self.data.select_dtypes(include=[bool]).columns.tolist()\n            self.data[bool_columns] = self.data[bool_columns].astype(int)\n    \n            numeric_columns = self.data.select_dtypes(include=[np.number]).columns.tolist()\n            print(f\"Step 4 - Selected Numeric Columns: {numeric_columns}\")\n    \n            if not numeric_columns:\n                print(\"ERROR: No numeric features found! Possible issue with encoding or missing numeric columns.\")\n            else:\n                self.data[numeric_columns] = self.data[numeric_columns].astype(np.float32)\n    \n            print(\"Step 5 - Final Processed Data Shape:\", self.data.shape)\n            print(\"Step 5 - Processed Columns:\", self.data.columns.tolist())\n            print(self.data.head())  # Print processed data to verify\n        else:\n            raise Exception(\"Data not loaded\")\n    def get_data(self):\n        return self.data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T06:40:26.285784Z","iopub.execute_input":"2025-08-10T06:40:26.286428Z","iopub.status.idle":"2025-08-10T06:40:26.297174Z","shell.execute_reply.started":"2025-08-10T06:40:26.286394Z","shell.execute_reply":"2025-08-10T06:40:26.295973Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"tabular_loader = TradeDataLoader()\ntabular_loader.load_data()\ntabular_loader.preprocess_data()\ntabular_data = tabular_loader.get_data()\nprint(tabular_loader.get_data().head())  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T06:40:26.298481Z","iopub.execute_input":"2025-08-10T06:40:26.298859Z","iopub.status.idle":"2025-08-10T06:40:26.996637Z","shell.execute_reply.started":"2025-08-10T06:40:26.298824Z","shell.execute_reply":"2025-08-10T06:40:26.995459Z"}},"outputs":[{"name":"stdout","text":"Data loaded from /kaggle/input/real-real-trading-dataset/Trading data.xlsx\nOriginal Tabular Data Shape: (100, 7)\n  Pair No Timeframe Number of Cs Price at 800 EMA Trade Type Hit 50EMA  \\\n0     EA1        D1          5-6              YES       SELL       YES   \n1     EA2        D1          6-7               NO       SELL        NO   \n2     EA3        D1          6-7               NO       SELL        NO   \n3     EA4        D1          4-5        NO-AT 200        BUY       YES   \n4     EA5        D1            3               NO       SELL        NO   \n\n                                       TP/SL  \n0          TP n SL could have been too close  \n1            SL- another leg top tho the LHS  \n2                                         SL  \n3  TP-trend was bearsh for a very short time  \n4                                         SL  \nStep 1 - Original Data Shape: (100, 7)\n  Pair No Timeframe Number of Cs Price at 800 EMA Trade Type Hit 50EMA  \\\n0     EA1        D1          5-6              YES       SELL       YES   \n1     EA2        D1          6-7               NO       SELL        NO   \n2     EA3        D1          6-7               NO       SELL        NO   \n3     EA4        D1          4-5        NO-AT 200        BUY       YES   \n4     EA5        D1            3               NO       SELL        NO   \n\n                                       TP/SL  \n0          TP n SL could have been too close  \n1            SL- another leg top tho the LHS  \n2                                         SL  \n3  TP-trend was bearsh for a very short time  \n4                                         SL  \nStep 2 - Unique TP/SL values before cleaning: ['TP n SL could have been too close' 'SL- another leg top tho the LHS'\n 'SL' 'TP-trend was bearsh for a very short time'\n 'TP - Trend was bearish for a very short time' 'TP'\n 'SL- Same pattern and shape as NC1'\n 'TRAILING SL- MISSED TP BY A FEW PIPS,MISSED       \\nSL BY A FEW PIPS ALSO'\n 'TRAILING SL- MISSED TP BY A FEW PIPS    '\n 'TP-BUT REVERSED IMMEDIATELY AFTER HITTING '\n 'TP-One support leg to the LHS ' 'SL-SL either hit/ missed by a few pips'\n 'TRAILING SL-TP MISSED BY A FEW PIPS' 'TP-SL WAS MISSED BY A FEW PIPS'\n 'TRAILING SL' 'SL-HIT BY LIKE 3 PIPS' 'SL-HIT BY LIKE 2-3 PIPS'\n 'TRAILING SL- TP MISSED BY LIKE 2-3 PIPS'\n 'TP-SL MISSED BY A FEW PIPS CZ OF THE SH' 'SL-HIT BY SPREAD/1 PIP'\n 'SL - HIT BY A FEW PIPS' 'SL-Very dangerous trade' 'SL-HIT BY 1 PIP'\n 'TP-SL Might have been hit, missed by 3-5 pips'\n 'SL-Wait for the setup to actuall form on the 800 \\nitself not just above but on the 800 or just below '\n 'G' 'GU' nan]\nStep 2 - Unique TP/SL values after cleaning: ['TP' 'SL' 'TRAILING SL' 'G' 'GU' nan]\nStep 2 - Unique Price at 800 EMA values after cleaning: ['YES' 'NO']\nStep 3 - Shape After Encoding: (100, 17)\nStep 3 - Columns After Encoding: ['Pair No', 'Number of Cs', 'Timeframe_D1', 'Timeframe_H1', 'Timeframe_H4', 'Timeframe_W1', 'Trade Type_BUY', 'Trade Type_SELL', 'TP/SL_G', 'TP/SL_GU', 'TP/SL_SL', 'TP/SL_TP', 'TP/SL_TRAILING SL', 'Price at 800 EMA_NO', 'Price at 800 EMA_YES', 'Hit 50EMA_NO', 'Hit 50EMA_YES']\nStep 4 - Selected Numeric Columns: ['Timeframe_D1', 'Timeframe_H1', 'Timeframe_H4', 'Timeframe_W1', 'Trade Type_BUY', 'Trade Type_SELL', 'TP/SL_G', 'TP/SL_GU', 'TP/SL_SL', 'TP/SL_TP', 'TP/SL_TRAILING SL', 'Price at 800 EMA_NO', 'Price at 800 EMA_YES', 'Hit 50EMA_NO', 'Hit 50EMA_YES']\nStep 5 - Final Processed Data Shape: (100, 17)\nStep 5 - Processed Columns: ['Pair No', 'Number of Cs', 'Timeframe_D1', 'Timeframe_H1', 'Timeframe_H4', 'Timeframe_W1', 'Trade Type_BUY', 'Trade Type_SELL', 'TP/SL_G', 'TP/SL_GU', 'TP/SL_SL', 'TP/SL_TP', 'TP/SL_TRAILING SL', 'Price at 800 EMA_NO', 'Price at 800 EMA_YES', 'Hit 50EMA_NO', 'Hit 50EMA_YES']\n  Pair No Number of Cs  Timeframe_D1  Timeframe_H1  Timeframe_H4  \\\n0     EA1          5-6           1.0           0.0           0.0   \n1     EA2          6-7           1.0           0.0           0.0   \n2     EA3          6-7           1.0           0.0           0.0   \n3     EA4          4-5           1.0           0.0           0.0   \n4     EA5            3           1.0           0.0           0.0   \n\n   Timeframe_W1  Trade Type_BUY  Trade Type_SELL  TP/SL_G  TP/SL_GU  TP/SL_SL  \\\n0           0.0             0.0              1.0      0.0       0.0       0.0   \n1           0.0             0.0              1.0      0.0       0.0       1.0   \n2           0.0             0.0              1.0      0.0       0.0       1.0   \n3           0.0             1.0              0.0      0.0       0.0       0.0   \n4           0.0             0.0              1.0      0.0       0.0       1.0   \n\n   TP/SL_TP  TP/SL_TRAILING SL  Price at 800 EMA_NO  Price at 800 EMA_YES  \\\n0       1.0                0.0                  0.0                   1.0   \n1       0.0                0.0                  1.0                   0.0   \n2       0.0                0.0                  1.0                   0.0   \n3       1.0                0.0                  1.0                   0.0   \n4       0.0                0.0                  1.0                   0.0   \n\n   Hit 50EMA_NO  Hit 50EMA_YES  \n0           0.0            1.0  \n1           1.0            0.0  \n2           1.0            0.0  \n3           0.0            1.0  \n4           1.0            0.0  \n  Pair No Number of Cs  Timeframe_D1  Timeframe_H1  Timeframe_H4  \\\n0     EA1          5-6           1.0           0.0           0.0   \n1     EA2          6-7           1.0           0.0           0.0   \n2     EA3          6-7           1.0           0.0           0.0   \n3     EA4          4-5           1.0           0.0           0.0   \n4     EA5            3           1.0           0.0           0.0   \n\n   Timeframe_W1  Trade Type_BUY  Trade Type_SELL  TP/SL_G  TP/SL_GU  TP/SL_SL  \\\n0           0.0             0.0              1.0      0.0       0.0       0.0   \n1           0.0             0.0              1.0      0.0       0.0       1.0   \n2           0.0             0.0              1.0      0.0       0.0       1.0   \n3           0.0             1.0              0.0      0.0       0.0       0.0   \n4           0.0             0.0              1.0      0.0       0.0       1.0   \n\n   TP/SL_TP  TP/SL_TRAILING SL  Price at 800 EMA_NO  Price at 800 EMA_YES  \\\n0       1.0                0.0                  0.0                   1.0   \n1       0.0                0.0                  1.0                   0.0   \n2       0.0                0.0                  1.0                   0.0   \n3       1.0                0.0                  1.0                   0.0   \n4       0.0                0.0                  1.0                   0.0   \n\n   Hit 50EMA_NO  Hit 50EMA_YES  \n0           0.0            1.0  \n1           1.0            0.0  \n2           1.0            0.0  \n3           0.0            1.0  \n4           1.0            0.0  \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"class ImageDataLoader:\n    def __init__(self, image_directory):\n        if not os.path.exists(image_directory):\n            raise FileNotFoundError(f\"Image directory {image_directory} not found!\")\n\n        self.image_directory = image_directory\n        self.image_data = {}\n\n    def load_images(self):\n        for file_name in os.listdir(self.image_directory):\n            if file_name.lower().endswith(\".png\") or file_name.lower().endswith(\".jpg\"):\n                pair_number = file_name.split('.')[0]  # Extract \"GU1\" from \"GU1.png\"\n                image_path = os.path.join(self.image_directory, file_name)\n\n                image = load_img(image_path, target_size=(256, 256), color_mode=\"grayscale\")\n                self.image_data[pair_number] = img_to_array(image)  # Save image data\n\n        print(f\"Loaded {len(self.image_data)} images from {self.image_directory}\")\n        print(\"Loaded image filenames:\", list(image_loader.image_data.keys()))\n\n\n    def get_image_data(self):\n        return self.image_data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T06:40:26.997683Z","iopub.execute_input":"2025-08-10T06:40:26.998282Z","iopub.status.idle":"2025-08-10T06:40:27.005463Z","shell.execute_reply.started":"2025-08-10T06:40:26.998251Z","shell.execute_reply":"2025-08-10T06:40:27.004171Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Load image data\nimage_loader = ImageDataLoader(\"/kaggle/input/real-real-trading-dataset/Image data\")\nimage_loader.load_images()\nimage_data = image_loader.get_image_data()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T06:40:27.007739Z","iopub.execute_input":"2025-08-10T06:40:27.008050Z","iopub.status.idle":"2025-08-10T06:40:28.522734Z","shell.execute_reply.started":"2025-08-10T06:40:27.008024Z","shell.execute_reply":"2025-08-10T06:40:28.521704Z"}},"outputs":[{"name":"stdout","text":"Loaded 100 images from /kaggle/input/real-real-trading-dataset/Image data\nLoaded image filenames: ['GA4', 'AU5', 'AF5', 'GA1', 'GU9', 'EC7', 'UC3', 'EN2', 'G11', 'EA4', 'G10', 'AF4', 'UD4', 'AF2', 'AU9', 'GU1', 'GA10', 'UD1', 'EG5', 'AU7', 'AU6', 'EA8', 'GU6', 'NU2', 'UC1', 'EC3', 'UD3', 'EN1', 'EA5', 'EG4', 'AF6', 'NC6', 'EN3', 'EG7', 'EG3', 'GA6', 'NC8', 'GU4', 'GN1', 'NU3', 'GU5', 'EA3', 'EC6', 'AU10', 'EG1', 'NU1', 'EC2', 'AF7', 'EU8', 'EA2', 'NC7', 'AF3', 'EU6', 'GU2', 'AU2', 'NC1', 'AU11', 'GA3', 'GA7', 'NC4', 'EC10', 'EA6', 'EU5', 'NC3', 'AU13', 'EC5', 'GA9', 'GA2', 'EU4', 'AU8', 'GU8', 'EG6', 'NC2', 'EG2', 'EC9', 'EU2', 'EU1', 'GU7', 'AU4', 'GU3', 'AU1', 'NC5', 'AU3', 'AU12', 'GA5', 'NU4', 'EA7', 'AF1', 'UC2', 'AC1', 'EU3', 'EU7', 'AF8', 'EC4', 'EC8', 'GA8', 'EA1', 'EC11', 'UD2', 'EC1']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"class TradeModelTrainer:\n    def __init__(self, tabular_data, image_data):\n        self.data = tabular_data\n        self.image_data = image_data\n        self.model = None\n\n    def check_rows_before_splitting(self):\n        print(\"Total Rows Before Split:\", len(self.data))\n\n    def preprocess_data(self):\n        images = list(self.image_data.values())\n        self.image_data = np.array(images).reshape(-1, 256, 256, 1)\n    \n        print(\"DEBUG: All Columns Before Selecting Numerics:\", self.data.columns.tolist())\n    \n        numeric_columns = self.data.select_dtypes(include=['number']).columns.tolist()\n        print(\"DEBUG: Numeric Columns Selected:\", numeric_columns)\n    \n        if not numeric_columns:\n            raise ValueError(\"ERROR: No numeric features found! Possible issue with encoding.\")\n    \n        self.tabular_data_features = self.data[numeric_columns].astype(np.float32)\n        print(\"DEBUG: Tabular Data Features Shape Before Split:\", self.tabular_data_features.shape)\n    \n        self.buy_sell_labels = self.data['Trade Type_BUY'].astype(np.float32).values\n        self.tp_sl_labels = self.data[[col for col in self.data.columns if col.startswith('TP/SL_')]].astype(np.float32).values\n    \n       \n        print(\"DEBUG: Buy/Sell Labels Shape:\", self.buy_sell_labels.shape)\n        print(\"DEBUG: TP/SL Labels Shape:\", self.tp_sl_labels.shape)\n    \n        self.train_features, self.test_features, self.train_images, self.test_images, \\\n        self.train_buy_sell, self.test_buy_sell, self.train_tp_sl, self.test_tp_sl = train_test_split(\n            self.tabular_data_features, self.image_data, self.buy_sell_labels, self.tp_sl_labels,\n            test_size=0.2, random_state=42\n        )\n    \n        print(\"DEBUG: Train Features Shape:\", self.train_features.shape)\n        print(\"DEBUG: Test Features Shape:\", self.test_features.shape)\n        print(\"Data preprocessed and split into train and test sets\")\n\n    def build_model(self):\n        image_input = Input(shape=(256, 256, 1), name='image_input')\n        x = Conv2D(32, (3, 3), activation='relu')(image_input)\n        x = MaxPooling2D((2, 2))(x)\n        x = Flatten()(x)  \n\n        tabular_input = Input(shape=(len(self.train_features.columns),), name='tabular_input')\n        y = Dense(64, activation='relu')(tabular_input)\n\n        combined = concatenate([x, y])\n        z = Dense(64, activation='relu')(combined)\n\n        buy_sell_output = Dense(1, activation='sigmoid', name='buy_sell_output')(z)\n        tp_sl_output = Dense(len(self.tp_sl_labels[0]), activation='softmax', name='tp_sl_output')(z)\n\n        self.model = Model(inputs=[image_input, tabular_input], outputs=[buy_sell_output, tp_sl_output])\n        self.model.compile(\n            optimizer=Adam(),\n            loss={'buy_sell_output': 'binary_crossentropy', 'tp_sl_output': 'categorical_crossentropy'},\n            metrics={'buy_sell_output': 'accuracy', 'tp_sl_output': 'accuracy'}\n        )\n\n        print(\"Model built successfully\")\n        print(\"Tabular Data Shape:\", self.train_features.shape)\n\n    def train_model(self):\n        self.model.fit(\n            [self.train_images, self.train_features],\n            {'buy_sell_output': self.train_buy_sell, 'tp_sl_output': self.train_tp_sl},\n            epochs=10,\n            batch_size=16,\n        )\n\n        print(\"Model trained\")\n\n    def test_model(self):\n        results = self.model.evaluate(\n            [self.test_images, self.test_features],\n            {'buy_sell_output': self.test_buy_sell, 'tp_sl_output': self.test_tp_sl}\n        )\n    \n        print(f\"Test Results: {results}\")  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T06:40:28.524139Z","iopub.execute_input":"2025-08-10T06:40:28.524431Z","iopub.status.idle":"2025-08-10T06:40:28.537603Z","shell.execute_reply.started":"2025-08-10T06:40:28.524408Z","shell.execute_reply":"2025-08-10T06:40:28.536355Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"trainer = TradeModelTrainer(tabular_data, image_data)\ntrainer.preprocess_data()\ntrainer.build_model()\ntrainer.train_model()\ntrainer.test_model()\ntrainer.check_rows_before_splitting()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T06:40:28.538692Z","iopub.execute_input":"2025-08-10T06:40:28.539095Z","iopub.status.idle":"2025-08-10T06:41:06.329936Z","shell.execute_reply.started":"2025-08-10T06:40:28.539057Z","shell.execute_reply":"2025-08-10T06:41:06.329048Z"}},"outputs":[{"name":"stdout","text":"DEBUG: All Columns Before Selecting Numerics: ['Pair No', 'Number of Cs', 'Timeframe_D1', 'Timeframe_H1', 'Timeframe_H4', 'Timeframe_W1', 'Trade Type_BUY', 'Trade Type_SELL', 'TP/SL_G', 'TP/SL_GU', 'TP/SL_SL', 'TP/SL_TP', 'TP/SL_TRAILING SL', 'Price at 800 EMA_NO', 'Price at 800 EMA_YES', 'Hit 50EMA_NO', 'Hit 50EMA_YES']\nDEBUG: Numeric Columns Selected: ['Timeframe_D1', 'Timeframe_H1', 'Timeframe_H4', 'Timeframe_W1', 'Trade Type_BUY', 'Trade Type_SELL', 'TP/SL_G', 'TP/SL_GU', 'TP/SL_SL', 'TP/SL_TP', 'TP/SL_TRAILING SL', 'Price at 800 EMA_NO', 'Price at 800 EMA_YES', 'Hit 50EMA_NO', 'Hit 50EMA_YES']\nDEBUG: Tabular Data Features Shape Before Split: (100, 15)\nDEBUG: Buy/Sell Labels Shape: (100,)\nDEBUG: TP/SL Labels Shape: (100, 5)\nDEBUG: Train Features Shape: (80, 15)\nDEBUG: Test Features Shape: (20, 15)\nData preprocessed and split into train and test sets\nModel built successfully\nTabular Data Shape: (80, 15)\nEpoch 1/10\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 662ms/step - buy_sell_output_accuracy: 0.4602 - buy_sell_output_loss: 736.2352 - loss: 1683.9014 - tp_sl_output_accuracy: 0.3828 - tp_sl_output_loss: 947.6663\nEpoch 2/10\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 651ms/step - buy_sell_output_accuracy: 0.4688 - buy_sell_output_loss: 673.2355 - loss: 1705.8010 - tp_sl_output_accuracy: 0.6316 - tp_sl_output_loss: 1032.5656\nEpoch 3/10\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 696ms/step - buy_sell_output_accuracy: 0.6257 - buy_sell_output_loss: 122.5889 - loss: 482.2085 - tp_sl_output_accuracy: 0.3082 - tp_sl_output_loss: 359.6196\nEpoch 4/10\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 637ms/step - buy_sell_output_accuracy: 0.8733 - buy_sell_output_loss: 26.1110 - loss: 99.0484 - tp_sl_output_accuracy: 0.7262 - tp_sl_output_loss: 72.9375\nEpoch 5/10\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 645ms/step - buy_sell_output_accuracy: 0.7993 - buy_sell_output_loss: 36.2393 - loss: 87.5000 - tp_sl_output_accuracy: 0.8179 - tp_sl_output_loss: 51.2606\nEpoch 6/10\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 652ms/step - buy_sell_output_accuracy: 0.9311 - buy_sell_output_loss: 14.6928 - loss: 17.1219 - tp_sl_output_accuracy: 0.9498 - tp_sl_output_loss: 2.4292      \nEpoch 7/10\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 637ms/step - buy_sell_output_accuracy: 0.9220 - buy_sell_output_loss: 8.8606 - loss: 14.7625 - tp_sl_output_accuracy: 0.9288 - tp_sl_output_loss: 5.9019\nEpoch 8/10\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 649ms/step - buy_sell_output_accuracy: 1.0000 - buy_sell_output_loss: 9.7049e-22 - loss: 2.7131 - tp_sl_output_accuracy: 0.9443 - tp_sl_output_loss: 2.7131    \nEpoch 9/10\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 647ms/step - buy_sell_output_accuracy: 1.0000 - buy_sell_output_loss: 2.4220e-16 - loss: 2.4220e-16 - tp_sl_output_accuracy: 0.9845 - tp_sl_output_loss: 0.0000e+00\nEpoch 10/10\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 638ms/step - buy_sell_output_accuracy: 1.0000 - buy_sell_output_loss: 3.0911e-26 - loss: 3.0911e-26 - tp_sl_output_accuracy: 1.0000 - tp_sl_output_loss: 0.0000e+00\nModel trained\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - buy_sell_output_accuracy: 0.8000 - buy_sell_output_loss: 41.8267 - loss: 84.9099 - tp_sl_output_accuracy: 0.7000 - tp_sl_output_loss: 43.0831\nTest Results: [84.90986633300781, 41.82672119140625, 43.0831413269043, 0.800000011920929, 0.699999988079071]\nTotal Rows Before Split: 100\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"trainer.model.save(\"/kaggle/working/tradin_model.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T06:41:06.330843Z","iopub.execute_input":"2025-08-10T06:41:06.331133Z","iopub.status.idle":"2025-08-10T06:41:07.190142Z","shell.execute_reply.started":"2025-08-10T06:41:06.331109Z","shell.execute_reply":"2025-08-10T06:41:07.189131Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"print(os.listdir(\"/kaggle/working/\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T06:41:07.191240Z","iopub.execute_input":"2025-08-10T06:41:07.191544Z","iopub.status.idle":"2025-08-10T06:41:07.196975Z","shell.execute_reply.started":"2025-08-10T06:41:07.191520Z","shell.execute_reply":"2025-08-10T06:41:07.195913Z"}},"outputs":[{"name":"stdout","text":"['.virtual_documents', 'tradin_model.h5']\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"model = tf.keras.models.load_model(\"/kaggle/working/tradin_model.h5\")\n\nfixed_input_shapes = [\n    tf.TensorSpec(shape=(None, 256, 256, 1), dtype=tf.float32, name=\"image_input\"),\n    tf.TensorSpec(shape=(None, 15), dtype=tf.float32, name=\"tabular_input\")  # Fix input shape for tabular data\n]\n\nonnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=fixed_input_shapes, opset=13)\n\n\nonnx.save_model(onnx_model, \"/kaggle/working/tradin_model.onnx\")\n\nprint(\" Model converted and saved as tradin_model.onnx\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T06:41:07.198042Z","iopub.execute_input":"2025-08-10T06:41:07.198421Z","iopub.status.idle":"2025-08-10T06:41:25.429741Z","shell.execute_reply.started":"2025-08-10T06:41:07.198389Z","shell.execute_reply":"2025-08-10T06:41:25.428621Z"}},"outputs":[{"name":"stdout","text":" Model converted and saved as tradin_model.onnx\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"pip install onnxruntime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T06:41:25.430862Z","iopub.execute_input":"2025-08-10T06:41:25.431186Z","iopub.status.idle":"2025-08-10T06:41:31.662791Z","shell.execute_reply.started":"2025-08-10T06:41:25.431141Z","shell.execute_reply":"2025-08-10T06:41:31.661454Z"}},"outputs":[{"name":"stdout","text":"Collecting onnxruntime\n  Downloading onnxruntime-1.22.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\nCollecting coloredlogs (from onnxruntime)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\nRequirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.2)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (2.4.1)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.6->onnxruntime) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.6->onnxruntime) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.6->onnxruntime) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.6->onnxruntime) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.6->onnxruntime) (2024.2.0)\nDownloading onnxruntime-1.22.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.22.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"pip install yfinance","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T06:41:31.664141Z","iopub.execute_input":"2025-08-10T06:41:31.664571Z","iopub.status.idle":"2025-08-10T06:41:35.920358Z","shell.execute_reply.started":"2025-08-10T06:41:31.664532Z","shell.execute_reply":"2025-08-10T06:41:35.918997Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.50)\nRequirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.2.2)\nRequirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.26.4)\nRequirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.32.3)\nRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\nRequirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (5.3.0)\nRequirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.3.6)\nRequirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2024.2)\nRequirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.6)\nRequirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.8)\nRequirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\nRequirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\nRequirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.17.0)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->yfinance) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->yfinance) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->yfinance) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->yfinance) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->yfinance) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->yfinance) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2024.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.12.14)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16.5->yfinance) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16.5->yfinance) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.16.5->yfinance) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.16.5->yfinance) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.16.5->yfinance) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import threading\nimport onnxruntime as ort\nimport time\nimport os\nimport yfinance as yf\nimport pandas as pd\nimport cv2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T06:41:35.921683Z","iopub.execute_input":"2025-08-10T06:41:35.922100Z","iopub.status.idle":"2025-08-10T06:41:36.901328Z","shell.execute_reply.started":"2025-08-10T06:41:35.922059Z","shell.execute_reply":"2025-08-10T06:41:36.900264Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import threading\nimport onnxruntime as ort\nimport time\nimport os\nimport yfinance as yf\nimport pandas as pd\nimport numpy as np\nimport cv2\n\nclass BotImplementation:\n    def __init__(self):\n        print(\"AI Trading Bot Initialized\")\n        self.session = ort.InferenceSession(\"/kaggle/working/tradin_model.onnx\")\n        print(\"AI Model Loaded Successfully\")\n        print(\"Checking model inputs:\")\n        for input_tensor in self.session.get_inputs():\n            print(f\"Input Name: {input_tensor.name}, Shape: {input_tensor.shape}, Type: {input_tensor.type}\")\n\n    def fetch_historical_data(self, symbol, timeframe=\"1d\", period=\"1y\"):\n        try:\n            print(f\"Fetching historical data for {symbol} ({timeframe}, {period})...\")\n            \n            # Try different variations of BTC symbol\n            symbols_to_try = [symbol, \"BTC-USD\", \"BTCUSD\", \"BTC\"]\n            df = None\n            \n            for sym in symbols_to_try:\n                try:\n                    df = yf.download(sym, period=period, interval=timeframe, progress=False)\n                    if not df.empty:\n                        print(f\"Successfully downloaded data using symbol: {sym}\")\n                        break\n                except:\n                    continue\n            \n            # If Yahoo Finance fails, try Ticker method\n            if df is None or df.empty:\n                print(\"Trying Ticker method...\")\n                try:\n                    ticker = yf.Ticker(\"BTC-USD\")\n                    df = ticker.history(period=period, interval=timeframe)\n                    if not df.empty:\n                        print(\"Ticker method successful!\")\n                except:\n                    pass\n                    \n            # If still no data, create sample data for testing\n            if df is None or df.empty:\n                print(\"Yahoo Finance unavailable. Creating sample BTC data for testing...\")\n                df = self._create_sample_btc_data()\n                if df is not None:\n                    print(\"✅ Using sample data for testing\")\n                \n            if df is None or df.empty:\n                print(f\"No data available for {symbol}.\")\n                return None\n                \n            df.reset_index(inplace=True)\n            # Handle both \"Date\" and \"Datetime\" column names\n            if \"Date\" in df.columns:\n                df.rename(columns={\"Date\": \"time\"}, inplace=True)\n            elif \"Datetime\" in df.columns:\n                df.rename(columns={\"Datetime\": \"time\"}, inplace=True)\n                \n            df.rename(columns={\"Open\": \"open\", \"High\": \"high\",\n                               \"Low\": \"low\", \"Close\": \"close\", \"Volume\": \"volume\"}, inplace=True)\n            print(f\"Historical data ready: {df.shape[0]} rows\")\n            return df\n        except Exception as e:\n            print(f\"Error fetching historical data for {symbol}: {e}\")\n            return None\n    \n    def _create_sample_btc_data(self):\n        \"\"\"Create sample BTC data when Yahoo Finance is unavailable\"\"\"\n        try:\n            dates = pd.date_range(end=pd.Timestamp.now(), periods=365, freq='D')\n            np.random.seed(42)  # For reproducible results\n            \n            # Generate realistic BTC price movement\n            base_price = 45000\n            price_changes = np.random.normal(0, 0.025, 365)  # 2.5% daily volatility\n            prices = [base_price]\n            \n            for change in price_changes[1:]:\n                new_price = prices[-1] * (1 + change)\n                prices.append(max(new_price, 1000))  # Minimum price floor\n            \n            # Create OHLCV data\n            sample_data = pd.DataFrame({\n                'time': dates,\n                'open': prices,\n                'high': [p * (1 + abs(np.random.normal(0, 0.015))) for p in prices],\n                'low': [p * (1 - abs(np.random.normal(0, 0.015))) for p in prices],\n                'close': prices,\n                'volume': np.random.randint(500000, 5000000, 365)\n            })\n            \n            # Ensure high >= max(open,close) and low <= min(open,close)\n            sample_data['high'] = sample_data[['open', 'close', 'high']].max(axis=1)\n            sample_data['low'] = sample_data[['open', 'close', 'low']].min(axis=1)\n            \n            return sample_data\n            \n        except Exception as e:\n            print(f\"Sample data creation failed: {e}\")\n            return None\n\n    def get_dynamic_candlestick_pattern(self, price_data):\n        # Use last 7 candles if available, else 3..7\n        min_candles, max_candles = 3, 7\n        available = len(price_data)\n        if available < min_candles:\n            return None\n        N = min(max_candles, available)\n        \n        # Extract last N rows [open, high, low, close] => (N,4)\n        patch = price_data[[\"open\",\"high\",\"low\",\"close\"]].values[-N:].astype(np.float32)\n        \n        # Normalize each column to [0,1] range\n        patch_min = patch.min(axis=0, keepdims=True)\n        patch_max = patch.max(axis=0, keepdims=True)\n        # Avoid division by zero\n        patch_range = patch_max - patch_min\n        patch_range[patch_range == 0] = 1.0\n        patch_normalized = (patch - patch_min) / patch_range\n        \n        # Convert to grayscale by averaging the 4 OHLC values\n        # This gives us (N,) array\n        grayscale_values = patch_normalized.mean(axis=1)\n        \n        # Create a simple 2D pattern by tiling the values\n        # We'll create a (N, N) matrix first, then resize to 256x256\n        pattern_2d = np.tile(grayscale_values.reshape(-1, 1), (1, N))\n        \n        # If we have fewer than 7 candles, pad to make it square\n        if N < 7:\n            pad_size = 7 - N\n            pattern_2d = np.pad(pattern_2d, ((0, pad_size), (0, pad_size)), mode='edge')\n            \n        # Now resize to 256x256\n        pattern_resized = cv2.resize(pattern_2d, (256, 256), interpolation=cv2.INTER_LINEAR)\n        \n        # Ensure it's in the right format and add batch and channel dimensions\n        image_4d = pattern_resized.astype(np.float32).reshape(1, 256, 256, 1)\n        \n        return image_4d, N\n\n    def detect_trade_pattern(self, symbol, timeframe):\n        price_data = self.fetch_historical_data(symbol, timeframe)\n        if price_data is None:\n            return None, 0, 0, None, None\n\n        result = self.get_dynamic_candlestick_pattern(price_data)\n        if result is None:\n            return None, 0, 0, None, None\n\n        image_input, pattern_length = result\n\n        # DO NOT resize again here - image_input is already (1, 256, 256, 1)\n        \n        # Build tabular vector of size 15\n        features = [\n            \"open\",\"high\",\"low\",\"close\",\"volume\",\n            \"50EMA\",\"200EMA\",\"800EMA\",\n            \"RSI\",\"MACD\",\"MACD_Signal\",\n            \"Bollinger_Upper\",\"Bollinger_Lower\",\n            \"ATR\",\"ADX\"\n        ]\n\n        # Ensure all 15 exist (fill with 0.0 if missing)\n        for f in features:\n            if f not in price_data.columns:\n                price_data[f] = 0.0\n\n        tabular = price_data.iloc[-1][features].values.astype(np.float32).reshape(1, 15)\n\n        # Run ONNX inference with BOTH inputs\n        output_name = self.session.get_outputs()[0].name\n        pred = self.session.run(\n            [output_name],\n            {\"image_input\": image_input, \"tabular_input\": tabular}\n        )\n\n        # Handle different prediction output shapes\n        if isinstance(pred[0], np.ndarray):\n            prob = float(pred[0].flatten()[0])\n        else:\n            prob = float(pred[0])\n        trade_type = \"BUY\" if prob > 0.5 else \"SELL\"\n        entry_price = float(price_data[\"close\"].iloc[-1])\n        trade_time = price_data[\"time\"].iloc[-1]\n\n        return trade_type, prob, pattern_length, entry_price, trade_time\n\n    def analyze_historical_patterns(self, symbol=\"BTC-USD\", timeframe=\"1d\", period=\"1y\"):\n        print(f\"Running AI pattern detection on {symbol} ({timeframe}) for {period} of historical data...\\n\")\n        trade_type, prob, N, entry, ts = self.detect_trade_pattern(symbol, timeframe)\n        if trade_type:\n            print(f\"TRADE ALERT: {symbol} ({timeframe})\")\n            print(f\"    • Trade Type: {trade_type}\")\n            print(f\"    • Probability: {prob:.4f}\")\n            print(f\"    • Entry Price: {entry}\")\n            print(f\"    • Time: {ts}\")\n            print(f\"    • Candles Used: {N}\")\n        else:\n            print(f\"No valid trade pattern detected for {symbol} ({timeframe})\")\n\n# Expected usage:\nbot = BotImplementation()\nbot.analyze_historical_patterns(\"BTC-USD\", \"1d\", \"1y\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T06:47:50.838931Z","iopub.execute_input":"2025-08-10T06:47:50.839389Z","iopub.status.idle":"2025-08-10T06:47:53.659793Z","shell.execute_reply.started":"2025-08-10T06:47:50.839354Z","shell.execute_reply":"2025-08-10T06:47:53.658740Z"}},"outputs":[{"name":"stdout","text":"✅ AI Trading Bot Initialized\n✅ AI Model Loaded Successfully\n📌 Checking model inputs:\n🔹 Input Name: image_input, Shape: ['unk__21', 256, 256, 1], Type: tensor(float)\n🔹 Input Name: tabular_input, Shape: ['unk__22', 15], Type: tensor(float)\n🧠 Running AI pattern detection on BTC-USD (1d) for 1y of historical data...\n\n🔍 Fetching historical data for BTC-USD (1d, 1y)...\nTrying Ticker method...\n⚠️ Yahoo Finance unavailable. Creating sample BTC data for testing...\n✅ Using sample data for testing\n✅ Historical data ready: 365 rows\n📈 TRADE ALERT: BTC-USD (1d)\n    • Trade Type: BUY\n    • Probability: 1.0000\n    • Entry Price: 43949.3173326369\n    • Time: 2025-08-10 06:47:53.635469\n    • Candles Used: 7\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"pip install yfinance --upgrade","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T06:41:40.212489Z","iopub.status.idle":"2025-08-10T06:41:40.212856Z","shell.execute_reply":"2025-08-10T06:41:40.212686Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}